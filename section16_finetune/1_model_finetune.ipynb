{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Section16: Model Fine tune technologies\n",
    "\n",
    "In this section, we will discuss model fine tune technologies. There are many `pre-trained` model we can use, from many source of data.\n",
    "\n",
    "With model fine tune, we can use the pre-trained model and train it with own data, which can save a lot of time and resources, and improve the model performance on our data set."
   ],
   "id": "e1647d77cb764974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:04:34.582343Z",
     "start_time": "2024-09-06T15:04:28.850231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Firstly let's import the necessary pytorch libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision"
   ],
   "id": "c6eed6978744d53b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:04:51.895208Z",
     "start_time": "2024-09-06T15:04:51.827220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "38618dbd0429081d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:05:22.713223Z",
     "start_time": "2024-09-06T15:05:22.706722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1024\n",
    "num_epochs = 5"
   ],
   "id": "68d7e08c80694852",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import the pre-trained model\n",
    "\n",
    "Firstly, we need a pre-trained model. We can use the `torchvision.models` to import the pre-trained model. \n",
    "\n",
    "In our section, we will use the `vgg16` model, which is a very popular model for image classification.\n",
    "\n",
    "Always bear in mind that remember to check first if there are any errors caused by the dimensions."
   ],
   "id": "92597efe75b3bdfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:18:36.463086Z",
     "start_time": "2024-09-06T15:17:58.524626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "print(model)"
   ],
   "id": "2a5b6e181afe0117",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\72403\\anaconda3\\envs\\pytorch4gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\72403\\anaconda3\\envs\\pytorch4gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\72403/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:36<00:00, 15.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## See the VGG model structure\n",
    "\n",
    "```\n",
    "VGG(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # input is 3 channels\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (3): ReLU(inplace=True)\n",
    "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (6): ReLU(inplace=True)\n",
    "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (8): ReLU(inplace=True)\n",
    "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (11): ReLU(inplace=True)\n",
    "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): ReLU(inplace=True)\n",
    "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (15): ReLU(inplace=True)\n",
    "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (18): ReLU(inplace=True)\n",
    "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (20): ReLU(inplace=True)\n",
    "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (22): ReLU(inplace=True)\n",
    "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (25): ReLU(inplace=True)\n",
    "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (27): ReLU(inplace=True)\n",
    "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (29): ReLU(inplace=True)\n",
    "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  # output here is going to be 7x7\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)  # should change this out_features to 10\n",
    "  )\n",
    ")\n",
    "```\n",
    "\n",
    "* Mind that we plan to use `CIFAR10` datasets, which has 10 classes. So the final classifier layer we need to change.\n",
    "* The `avgpool` layer is used to convert the output to a 7x7 feature map. We do not need it."
   ],
   "id": "33a4e541461542d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:34:21.950293Z",
     "start_time": "2024-09-06T15:34:21.941396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a simple block to do the remove the avgpool layer thing\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ],
   "id": "34b2f72bcf3904d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:35:28.821982Z",
     "start_time": "2024-09-06T15:35:28.809037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modify the avgpooling\n",
    "model.avgpool = Identity()\n",
    "\n",
    "# Hint: if there are many avgpooling layers, we can use the following code to remove all of them\n",
    "# model.avgpool[0 or 1 or else index] = nn.Identity()"
   ],
   "id": "486728cfe093edfc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:36:12.422103Z",
     "start_time": "2024-09-06T15:36:12.349774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change the classifier layer\n",
    "model.classifier = nn.Linear(512, num_classes)"
   ],
   "id": "70c539629623ed65",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:36:15.369937Z",
     "start_time": "2024-09-06T15:36:15.350899Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "955d29c9a141d6a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): Identity()\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:39:00.999668Z",
     "start_time": "2024-09-06T15:39:00.990377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# also can use nn.Sequential to modify the model\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(512, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(100, num_classes)\n",
    ")"
   ],
   "id": "90c8dac3114ec296",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:40:00.070399Z",
     "start_time": "2024-09-06T15:39:59.892462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# try to run the model\n",
    "model.to(device=device)"
   ],
   "id": "589fcfa0e2c11db2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): Identity()\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:50:45.280617Z",
     "start_time": "2024-09-06T15:48:27.195173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "accuracy_record = []\n",
    "loss_function_record = []\n",
    "\n",
    "# Define the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "    \n",
    "    for batch_index, (data, targets) in enumerate(train_loader):  # data is x and targets is y\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate the loss\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs, dim=1)  # return the max value and the index\n",
    "        corrects = torch.sum(preds == targets.data).item()\n",
    "        accuracy = corrects / batch_size\n",
    "        epoch_accuracy.append(accuracy)\n",
    "        \n",
    "    \n",
    "    # record average loss and accuracy\n",
    "    accuracy_record.append(sum(epoch_accuracy) / len(epoch_accuracy))\n",
    "    loss_function_record.append(sum(epoch_loss) / len(epoch_loss))\n",
    "    \n",
    "    \n",
    "    print(f'Epoch {epoch} finished with loss: {sum(epoch_loss) / len(epoch_loss)} and accuracy: {sum(epoch_accuracy) / len(epoch_accuracy)}')"
   ],
   "id": "4355823dcea0a830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:24<00:00, 7069880.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Epoch 0 finished with loss: 2.29251242657097 and accuracy: 0.11102917729591837\n",
      "Epoch 1 finished with loss: 2.03654669742195 and accuracy: 0.1738879145408163\n",
      "Epoch 2 finished with loss: 1.7467342955725533 and accuracy: 0.285335618622449\n",
      "Epoch 3 finished with loss: 1.36225582628834 and accuracy: 0.4832389987244898\n",
      "Epoch 4 finished with loss: 0.9716040662356785 and accuracy: 0.6501713966836735\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d5c35bca7fd0a8bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
