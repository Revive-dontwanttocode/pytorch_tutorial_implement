{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98da01c",
   "metadata": {},
   "source": [
    "# Runnning an ONNX Model with ONNX Runtime!\n",
    "Now that we have our model in the ONNX formate we can use ONNX Runtime perform inference with our model!<br>\n",
    "[ONNX Runtime](https://onnxruntime.ai/)<br>\n",
    "ONNX Runtime is not only avaliable as a Python library, but has versions in:\n",
    "* C++\n",
    "* C\n",
    "* C#\n",
    "* Java\n",
    "* JavaScript\n",
    "* Objective-C\n",
    "* Julia and Ruby APIs \n",
    "<br>\n",
    "<br>\n",
    "All of which can use the same ONNX file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "from PIL import Image\n",
    "import json\n",
    "import time\n",
    "\n",
    "## You will need to Install onnxruntime\n",
    "\n",
    "# If you don't have a GPU install cpu version\n",
    "# pip install onnxruntime\n",
    "\n",
    "# If you have a GPU install gpu version\n",
    "# pip install onnxruntime-gpu\n",
    "\n",
    "# Make sure you install the correct version for your version of CUDA!\n",
    "# Also check dependencies!\n",
    "# https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\n",
    "# EG for CUDA version 12.2 use \n",
    "# pip install onnxruntime-gpu==1.17\n",
    "\n",
    "# NOTE Pytorch has it's own cuDNN that gets installed with torch\n",
    "# If you want to use other applications that need cuDNNm like onnxruntime-gpu (without having to import torch)\n",
    "# You need to install cuDNN separately (it doesn't come with NVIDIA Toolkit)\n",
    "# NOTE: at time of writing only cuDNN 8.X versions are supported!!\n",
    "# https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-890/install-guide/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51feda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ONNX Runtime inference session with GPU support\n",
    "ort_session = onnxruntime.InferenceSession(\"./efficientnet_b1.onnx\", providers=['CUDAExecutionProvider'])\n",
    "\n",
    "# Load image classification labels from JSON file (assuming labels are in imagenet_classes.json)\n",
    "with open(\"../../data/imagenet_classes.json\", \"r\") as file:\n",
    "    img_net_classes = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ed165",
   "metadata": {},
   "source": [
    "## Create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize(image, new_size):\n",
    "    # Get the dimensions of the original image\n",
    "    width, height = image.size\n",
    "\n",
    "    # Calculate the size of the square crop\n",
    "    min_dim = min(width, height)\n",
    "\n",
    "    # Calculate coordinates for the center crop\n",
    "    left = (width - min_dim) // 2\n",
    "    upper = (height - min_dim) // 2\n",
    "    right = left + min_dim\n",
    "    lower = upper + min_dim\n",
    "\n",
    "    # Crop the image to a square\n",
    "    square_image = image.crop((left, upper, right, lower))\n",
    "\n",
    "    # Resize the image to the specified size\n",
    "    resized_image = square_image.resize((new_size, new_size))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalise_reshape(image, mean, std):\n",
    "    # Get image dimensions (height, width, channels)\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    # Move channel dimension to the front (assuming PyTorch format) and normalize pixel values by 255\n",
    "    image = image.transpose((2, 0, 1)) / 255.0  \n",
    "\n",
    "    # Reshape mean and std into numpy arrays with proper dimensions for broadcasting\n",
    "    np_means = np.array(mean).reshape(c, 1, 1)  \n",
    "    np_stds = np.array(std).reshape(c, 1, 1)  \n",
    "\n",
    "    # Normalize the image by subtracting the mean and dividing by the standard deviation (with epsilon for stability)\n",
    "    norm_image = (image - np_means) / (np_stds + 1e-6)\n",
    "\n",
    "    # Expand the dimension at index 0 to create a batch dimension (assuming batch size of 1)\n",
    "    # and cast the data type to float32 for compatibility with most models\n",
    "    return np.expand_dims(norm_image, 0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaae5d7",
   "metadata": {},
   "source": [
    "## Load and test ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming a function 'crop_resize' exists for image cropping and resizing\n",
    "test_image = crop_resize(Image.open(\"../../data/dog.jpg\"), 224)\n",
    "\n",
    "# 'test_image' now holds the cropped and resized image from the dog.jpg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PIL image to numpy array\n",
    "np_image = np.array(test_image)\n",
    "\n",
    "# Define mean and standard deviation values (assuming these are for normalization)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Normalize and reshape the image for inference using the 'image_normalise_reshape' function\n",
    "norm_image = image_normalise_reshape(np_image, mean, std)\n",
    "\n",
    "# Comment about batch processing (not implemented in this code block)\n",
    "# Should also work with batch of images!\n",
    "# norm_image_batch = np.concatenate((norm_image, norm_image), 0)\n",
    "\n",
    "# Prepare input data for ONNX Runtime session\n",
    "onnxruntime_input = {ort_session.get_inputs()[0].name: norm_image}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ee73f",
   "metadata": {},
   "source": [
    "## How fast is inference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9314dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store inference times\n",
    "inference_time = []\n",
    "\n",
    "# Perform multiple inference runs (10 in this case)\n",
    "for _ in range(10):\n",
    "  # Record start time\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Run inference using ONNX Runtime session\n",
    "  onnxruntime_outputs = ort_session.run(None, onnxruntime_input)\n",
    "\n",
    "  # Record end time\n",
    "  end_time = time.time()\n",
    "\n",
    "  # Calculate and store inference time for this run\n",
    "  inference_time.append(end_time - start_time)\n",
    "\n",
    "# Print the minimum inference time observed across the runs\n",
    "print(\"Minimum inference time %.4fs\" % np.min(inference_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c428abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the outputs from ONNX Runtime inference\n",
    "print(\"ONNX Runtime outputs:\")\n",
    "for output in onnxruntime_outputs:\n",
    "    # Get the predicted class index (assuming the output represents class probabilities)\n",
    "    class_index = np.argmax(output)\n",
    "    print(\"Class index:\", class_index)\n",
    "\n",
    "    # Assuming 'img_net_classes' is a dictionary mapping class indices to labels\n",
    "    # Look up the class label corresponding to the predicted class index\n",
    "    print(\"Class Label:\", img_net_classes.get(str(class_index)))  # No code change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
