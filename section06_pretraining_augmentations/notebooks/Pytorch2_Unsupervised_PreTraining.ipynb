{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised PreTraining\n",
    "\n",
    "We may encounter this scene: we have no such large amount of data, and labels. In this case, we need to use so-called `Pre-Train` model and `Fine-Tuning` methodology to solve this problem.\n",
    "\n",
    "In this part, we will use `STL10` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STL-10 dataset\n",
    "The STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms. It is inspired by the `CIFAR-10` dataset but with some modifications. In particular, each class has **fewer labeled training examples than in CIFAR-10**, but a very **large set of unlabeled examples** is provided to learn image models prior to supervised training. The primary challenge is to make use of the unlabeled data (which comes from a similar but different distribution from the labeled data) to build a useful prior. We also expect that the higher resolution of this dataset (96x96) will make it a challenging benchmark for developing more scalable unsupervised learning methods.\n",
    "### Overview\n",
    "\n",
    "* 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.\n",
    "* Images are 96x96 pixels, color.\n",
    "* 500 training images (10 pre-defined folds), 800 test images per class.\n",
    "* 100000 unlabeled images for unsupervised learning. These examples are extracted from a similar but broader distribution of images. For instance, it contains other types of animals (bears, rabbits, etc.) and vehicles (trains, buses, etc.) in addition to the ones in the labeled set.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our target\n",
    "\n",
    "We want to use these **unlabled images** to pre-train a model, and then take the labeled images with the pre-trained model and find it to be a classifier."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sb01NHS5PMS8",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:43.854528Z",
     "start_time": "2024-09-05T15:31:39.966807Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as FT\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "import torchvision.models as models\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "from Trainer import ModelTrainer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUaeH517PMS_",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:52.766080Z",
     "start_time": "2024-09-05T15:31:52.752027Z"
    }
   },
   "source": [
    "# The size of our mini batches\n",
    "batch_size = 64\n",
    "\n",
    "# How many itterations of our dataset\n",
    "num_epochs = 30\n",
    "\n",
    "# Optimizer learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Where to load/save the dataset from \n",
    "data_set_root = \"../../datasets\"\n",
    "\n",
    "# What to resize our images to \n",
    "image_size = 96"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVGVcxx0PMTB",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:53.498139Z",
     "start_time": "2024-09-05T15:31:53.493600Z"
    }
   },
   "source": [
    "start_from_checkpoint = False\n",
    "\n",
    "save_dir = '../data/Models'\n",
    "model_name = 'ResNet18_STL10_Rotate'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRJXAwTXPMTD",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:54.710583Z",
     "start_time": "2024-09-05T15:31:54.663012Z"
    }
   },
   "source": [
    "# Set device to GPU_indx if GPU is avaliable\n",
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wDY0BijPMTF"
   },
   "source": [
    "### DataSets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:55.744284Z",
     "start_time": "2024-09-05T15:31:55.737681Z"
    }
   },
   "source": [
    "# Create a STL10 dataset by inheriting Pytorch's exisitng STL10 \n",
    "# and re-defining the __getitem__ method\n",
    "class RotateSTL10(datasets.STL10):\n",
    "    # Define a list of different angles to roate the image by\n",
    "    all_perms = [0, 45, 90, 135, 180, 225, 270]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "            # Select image using index\n",
    "            img = self.data[index]\n",
    "            \n",
    "            # doing this so that it is consistent with all other datasets\n",
    "            # to return a PIL Image\n",
    "            img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
    "            \n",
    "            # Randomly select an angle from the list to rotate the image by\n",
    "            rand_int = random.randint(0, len(self.all_perms) - 1)\n",
    "            img = FT.rotate(img, angle=self.all_perms[rand_int])\n",
    "\n",
    "            # Add additional transforms\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            # Return roated image and the index of the selected angle\n",
    "            return img, rand_int"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:58.181528Z",
     "start_time": "2024-09-05T15:31:58.170011Z"
    }
   },
   "source": [
    "# Create a STL10 dataset by inheriting Pytorch's exisitng STL10 \n",
    "# and re-defining the __getitem__ method\n",
    "class ShuffleSTL10(datasets.STL10):\n",
    "    \n",
    "    # Define the hight and width of the \"puzzle\" grid !\n",
    "    puzzle_size = 3\n",
    "    # Set the maximum number of permutations\n",
    "    max_perms = 100\n",
    "    \n",
    "    # Determine all possible permutations of the puzzle pieces\n",
    "    iter_array = itertools.permutations(np.arange(puzzle_size**2))\n",
    "    all_perms = []\n",
    "    for arr in iter_array:\n",
    "        all_perms.append(torch.tensor([arr]))\n",
    "        \n",
    "        if len(all_perms) == max_perms:\n",
    "            break\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            # Select image using index\n",
    "            img = self.data[index]\n",
    "            \n",
    "            # doing this so that it is consistent with all other datasets\n",
    "            # to return a PIL Image\n",
    "            img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "                \n",
    "            # Determine number of pixels per puzzel piece\n",
    "            img_size = img.shape[-1]\n",
    "            puzzle_sections = self.puzzle_size**2\n",
    "            \n",
    "            # Use Pytorch Shuffle and UnShuffle to move pieces around\n",
    "            unshuffle = nn.PixelUnshuffle(img_size//self.puzzle_size)\n",
    "            shuffle = nn.PixelShuffle(img_size//self.puzzle_size)\n",
    "            \n",
    "            # Randomly select one permutation of the puzzle\n",
    "            rand_int = random.randint(0, len(self.all_perms) - 1)\n",
    "            perm = self.all_perms[rand_int]\n",
    "            \n",
    "            # Shuffle the puzzle pieces\n",
    "            img_out = unshuffle(img.unsqueeze(0))\n",
    "            img_out = img_out.reshape(1, img.shape[0], -1, puzzle_sections)\n",
    "            img_out = shuffle(img_out[:, :, :, perm].reshape(1, -1, \n",
    "                                                                  self.puzzle_size, \n",
    "                                                                  self.puzzle_size))\n",
    "\n",
    "            return img_out.squeeze(0), rand_int"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "keIwAFK-PMTG",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:31:59.304370Z",
     "start_time": "2024-09-05T15:31:59.295364Z"
    }
   },
   "source": [
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7L2lrkdPMTM"
   },
   "source": [
    "# Create the training, testing and validation data "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29503,
     "status": "ok",
     "timestamp": 1568947936500,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "5FyAAqHWPMTM",
    "outputId": "d566a865-6439-47d3-a195-6b897199d923",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:32:12.502299Z",
     "start_time": "2024-09-05T15:32:00.300250Z"
    }
   },
   "source": [
    "# Define our STL10 Datasets\n",
    "# https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.STL10\n",
    "\n",
    "# Dataset definition is a bit differenet to MNIST and CIFAR10\n",
    "# STL10 has 3 different datasets, test, train and unlabeled\n",
    "# http://ai.stanford.edu/~acoates/stl10/\n",
    "# training set only has 5000 images and test set only 8000\n",
    "# Image size in this dataset are 96x96, larger then what we've been using\n",
    "\n",
    "train_data = RotateSTL10(data_set_root, split='train+unlabeled', download=True, transform=transform)  # include trainning set without labels\n",
    "test_data = RotateSTL10(data_set_root, split='test', download=True, transform=transform)\n",
    "\n",
    "# Split trainging data into train and validation set with 90/10% traning/validation split\n",
    "validation_split = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data)*validation_split)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [n_train_examples, n_valid_examples],\n",
    "                                                       generator=torch.Generator().manual_seed(42))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a network\n",
    "Use one of Pytorch's [implementation](https://pytorch.org/vision/0.14/models.html) of a Classifier!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34657,
     "status": "ok",
     "timestamp": 1568947941813,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "JQPwhQuaPMTd",
    "outputId": "000d7dfc-5cd1-4afc-ef52-d7c1c7cc2754",
    "ExecuteTime": {
     "end_time": "2024-09-05T15:35:22.951308Z",
     "start_time": "2024-09-05T15:35:22.742149Z"
    }
   },
   "source": [
    "# Create an instance of the ResNet18 Model\n",
    "# You can also try other model architechtures!\n",
    "res_net = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) "
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:35:24.479650Z",
     "start_time": "2024-09-05T15:35:24.351167Z"
    }
   },
   "source": [
    "num_outputs = len(train_data.dataset.all_perms)\n",
    "\n",
    "model_trainer = ModelTrainer(model=res_net, output_size=num_outputs, device=device, \n",
    "                             loss_fun=nn.CrossEntropyLoss(), \n",
    "                             batch_size=batch_size, learning_rate=learning_rate, \n",
    "                             save_dir=save_dir, model_name=model_name, \n",
    "                             start_from_checkpoint=start_from_checkpoint)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from scratch\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:35:25.196491Z",
     "start_time": "2024-09-05T15:35:25.191492Z"
    }
   },
   "source": [
    "model_trainer.set_data(train_set=train_data, test_set=test_data, val_set=valid_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 94500\n",
      "Number of validation examples: 10500\n",
      "Number of testing examples: 8000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## View Data\n",
    "\n",
    "Lets take a look at some of the images in our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Learning Rate Scheduler\n",
    "We can dynamically change the <a href=\"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\">learning rate</a> during training to help our model converge to a better minimum!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:35:44.985987Z",
     "start_time": "2024-09-05T15:35:44.972477Z"
    }
   },
   "source": [
    "# Uncomment one of these and try it out!\n",
    "\n",
    "model_trainer.set_lr_schedule(optim.lr_scheduler.StepLR(model_trainer.optimizer, \n",
    "                                                        step_size=1, \n",
    "                                                        gamma=0.95))\n",
    "\n",
    "# model_trainer.set_lr_schedule(optim.lr_scheduler.CosineAnnealingLR(model_trainer.optimizer, \n",
    "#                                                                    T_max=num_epochs, \n",
    "#                                                                    eta_min=0))"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:36:05.384853Z",
     "start_time": "2024-09-05T15:36:05.371700Z"
    }
   },
   "source": [
    "# Lets see how many Parameter's our Model has!\n",
    "num_params = 0\n",
    "for param in model_trainer.model.parameters():\n",
    "    num_params += param.flatten().shape[0]\n",
    "print(\"This model has %d (approximately %d Million) Parameters!\" % (num_params, num_params//1e6))\n",
    "# Train Model!\n",
    "Our full training method is now fully contained within the trainner class! Simply run the run_training method and specify how many epochs it should train for!"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 11180103 (approximately 11 Million) Parameters!\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1568948678396,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "K27MEsO5PMT-",
    "outputId": "0c03f2f2-e250-4fad-dae5-b0dbaad8bda4",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-09-05T15:43:10.545268300Z",
     "start_time": "2024-09-05T15:36:10.116129Z"
    }
   },
   "source": [
    "model_trainer.run_training(num_epochs=num_epochs)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35b30901a50f4178a7d9f9c0aae518fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/1477 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83f6256cce7045cfab0a222d8ab6e498"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The highest validation accuracy was %.2f%%\" %(model_trainer.best_valid_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1568948455980,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "HoLp_P3xPMUE",
    "outputId": "b241900f-ff45-42f0-dc33-14b48126836f"
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10,5))\n",
    "train_x = np.linspace(0, num_epochs, len(model_trainer.train_loss_logger))\n",
    "_ = plt.plot(train_x, model_trainer.train_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10,5))\n",
    "train_x = np.linspace(0, num_epochs, len(model_trainer.train_acc_logger))\n",
    "_ = plt.plot(train_x, model_trainer.train_acc_logger, c = \"y\")\n",
    "valid_x = np.linspace(0, num_epochs, len(model_trainer.val_acc_logger))\n",
    "_ = plt.plot(valid_x, model_trainer.val_acc_logger, c = \"k\")\n",
    "\n",
    "_ = plt.title(\"Accuracy\")\n",
    "_ = plt.legend([\"Training accuracy\", \"Validation accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_F2Qy9WPMUG"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1568948469315,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -600
    },
    "id": "dKMx57tEPMUH",
    "outputId": "7590031a-2a9e-4701-9799-320155e5efd6"
   },
   "outputs": [],
   "source": [
    "# Call the evaluate function and pass the evaluation/test dataloader etc\n",
    "test_acc = model_trainer.evaluate_model(train_test_val=\"test\")\n",
    "print(\"The Test Accuracy is: %.2f%%\" %(test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet18_STL10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
